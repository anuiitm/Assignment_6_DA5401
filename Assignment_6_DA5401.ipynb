{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2aeda10"
      },
      "source": [
        "# Task\n",
        "Load the dataset \"UCI_Credit_Card.csv\", artificially introduce Missing At Random (MAR) values (5-10% in 2-3 numerical feature columns), and identify the target variable 'default payment next month'. Then, apply three different imputation strategies: Simple Imputation (median), Linear Regression Imputation, and Non-Linear Regression Imputation (using KNN or Decision Tree) to handle the missing values. Explain the rationale behind using the median for simple imputation and the MAR assumption for regression imputation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9080bc08"
      },
      "source": [
        "## Load and prepare data\n",
        "\n",
        "### Subtask:\n",
        "Load the dataset, introduce 5-10% MAR missing values in 2-3 numerical columns, and identify the target variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "c01a6db4",
        "outputId": "f3bb8640-430c-4420-b65f-ea4aee216e7a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('UCI_Credit_Card.csv')\n",
        "target_variable = 'default.payment.next.month'\n",
        "id_column = 'ID'\n",
        "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "numerical_cols.remove(target_variable)\n",
        "numerical_cols.remove(id_column)\n",
        "np.random.seed(42)\n",
        "cols_to_mar = np.random.choice(numerical_cols, size=3, replace=False)\n",
        "for col in cols_to_mar:\n",
        "    median_age = df['AGE'].median()\n",
        "    mar_condition = df['AGE'] > median_age\n",
        "    rows_to_mar_indices = df[mar_condition].sample(frac=np.random.uniform(0.05, 0.10), replace=False).index\n",
        "    df.loc[rows_to_mar_indices, col] = np.nan\n",
        "print(\"Missing values introduced:\")\n",
        "for col in cols_to_mar:\n",
        "    print(f\"{col}: {df[col].isnull().sum()} ({df[col].isnull().sum()/len(df):.2%})\")\n",
        "display(df.head())\n",
        "print(f\"\\nTarget variable: {target_variable}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values introduced:\n",
            "BILL_AMT5: 933 (3.11%)\n",
            "PAY_5: 1013 (3.38%)\n",
            "LIMIT_BAL: 1104 (3.68%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
              "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
              "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
              "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
              "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
              "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
              "\n",
              "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
              "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
              "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
              "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
              "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
              "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
              "\n",
              "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
              "0       0.0       0.0       0.0                           1  \n",
              "1    1000.0       0.0    2000.0                           1  \n",
              "2    1000.0    1000.0    5000.0                           0  \n",
              "3    1100.0    1069.0    1000.0                           0  \n",
              "4    9000.0     689.0     679.0                           0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3d2c5c5-fd5a-4234-bbae-bb5511021d09\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>...</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default.payment.next.month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3272.0</td>\n",
              "      <td>3455.0</td>\n",
              "      <td>3261.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>14331.0</td>\n",
              "      <td>14948.0</td>\n",
              "      <td>15549.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>28314.0</td>\n",
              "      <td>28959.0</td>\n",
              "      <td>29547.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20940.0</td>\n",
              "      <td>19146.0</td>\n",
              "      <td>19131.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3d2c5c5-fd5a-4234-bbae-bb5511021d09')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3d2c5c5-fd5a-4234-bbae-bb5511021d09 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3d2c5c5-fd5a-4234-bbae-bb5511021d09');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6813d432-87e2-4224-9412-7c1646ee3768\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6813d432-87e2-4224-9412-7c1646ee3768')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6813d432-87e2-4224-9412-7c1646ee3768 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target variable: default.payment.next.month\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94bdf189"
      },
      "source": [
        "## Imputation strategy 1: simple imputation (baseline)\n",
        "\n",
        "### Subtask:\n",
        "Create a copy of the dataset (Dataset A), impute missing values with the median for each column, and explain the preference for the median over the mean.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e053411d",
        "outputId": "eb32b5f0-10b4-4e08-b2f9-ad6babc2cc6e"
      },
      "source": [
        "df_a = df.copy()\n",
        "cols_with_missing = df_a.columns[df_a.isnull().any()].tolist()\n",
        "for col in cols_with_missing:\n",
        "    median_val = df_a[col].median()\n",
        "    df_a[col].fillna(median_val, inplace=True)\n",
        "print(\"Missing values after median imputation:\")\n",
        "for col in cols_with_missing:\n",
        "    print(f\"{col}: {df_a[col].isnull().sum()}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after median imputation:\n",
            "LIMIT_BAL: 0\n",
            "PAY_5: 0\n",
            "BILL_AMT5: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2923217904.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_a[col].fillna(median_val, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation for using median over mean for imputation:\n",
        "- The median is often preferred over the mean for simple imputation, especially when dealing with potential outliers.\n",
        "- This is because the median is a robust statistic that is not significantly affected by extreme values (outliers),\n",
        "whereas the mean can be skewed by outliers. When imputing missing data, using the median provides a more representative\n",
        "central tendency for the data, leading to less biased imputation results in the presence of outliers."
      ],
      "metadata": {
        "id": "UL-hmprIAmWX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5075dd67"
      },
      "source": [
        "## Imputation strategy 2: regression imputation (linear)\n",
        "\n",
        "### Subtask:\n",
        "Create a copy of the dataset (Dataset B), use Linear Regression to impute missing values in a chosen column, and explain the MAR assumption.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa2161c6",
        "outputId": "bf36297e-1c6a-499b-cf2d-095f8a598ef6"
      },
      "source": [
        "df_b = df.copy()\n",
        "missing_counts = df_b[['BILL_AMT5', 'PAY_5', 'LIMIT_BAL']].isnull().sum()\n",
        "print(\"Missing values in potential target columns for imputation:\\n\", missing_counts)\n",
        "target_column_imputation = 'BILL_AMT5'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in potential target columns for imputation:\n",
            " BILL_AMT5     933\n",
            "PAY_5        1013\n",
            "LIMIT_BAL    1104\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30418ed3",
        "outputId": "d313e09f-bd82-4551-9493-e5a862501e7c"
      },
      "source": [
        "missing_rows = df_b[df_b[target_column_imputation].isnull()]\n",
        "non_missing_rows = df_b[df_b[target_column_imputation].notnull()]\n",
        "numerical_cols = df_b.select_dtypes(include=np.number).columns.tolist()\n",
        "feature_cols = [col for col in numerical_cols if col not in [target_column_imputation, 'ID', 'default.payment.next.month']]\n",
        "X_train = non_missing_rows[feature_cols]\n",
        "y_train = non_missing_rows[target_column_imputation]\n",
        "X_predict = missing_rows[feature_cols]\n",
        "print(f\"Shape of training features (X_train): {X_train.shape}\")\n",
        "print(f\"Shape of training target (y_train): {y_train.shape}\")\n",
        "print(f\"Shape of prediction features (X_predict): {X_predict.shape}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training features (X_train): (29067, 22)\n",
            "Shape of training target (y_train): (29067,)\n",
            "Shape of prediction features (X_predict): (933, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOsZSj7L69bK",
        "outputId": "6d1fa2ab-c41d-4ba5-f685-4ca706cca517"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "lin_reg = LinearRegression()\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "imputer.fit(X_train)\n",
        "X_train_imputed = imputer.transform(X_train)\n",
        "X_predict_imputed = imputer.transform(X_predict)\n",
        "lin_reg.fit(X_train_imputed, y_train)\n",
        "predicted_values = lin_reg.predict(X_predict_imputed)\n",
        "df_b.loc[missing_rows.index, target_column_imputation] = predicted_values\n",
        "print(f\"\\nMissing values in '{target_column_imputation}' after linear regression imputation: {df_b[target_column_imputation].isnull().sum()}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in 'BILL_AMT5' after linear regression imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Explanation of Missing At Random (MAR) Assumption:\n",
        "- Missing At Random (MAR) means that the probability of a value being missing depends on the observed data, but not on the missing value itself.\n",
        "- In the context of using regression for imputation, the MAR assumption implies that the relationship between the missing variable (the target column for imputation) and the observed variables (the features used in the regression model) is sufficient to explain the missingness.\n",
        "- Essentially, if we know the values of the features, we can predict the missing value of the target variable, and the fact that the value is missing does not provide additional information about its value beyond what the observed features tell us.\n",
        "- For example, if the missingness in 'BILL_AMT5' is related to a person's 'AGE', as we artificially introduced, and we use 'AGE' (and other relevant features) to predict 'BILL_AMT5', we are assuming MAR.\n",
        "- If, however, the missingness in 'BILL_AMT5' was related to the *actual value* of 'BILL_AMT5' (e.g., people with very high bills are more likely to have missing entries), then the data would be Missing Not At Random (MNAR), and regression imputation based on observed features alone would likely produce biased results."
      ],
      "metadata": {
        "id": "y9LCS5lm9-ej"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ca8f6b"
      },
      "source": [
        "## Imputation strategy 3: regression imputation (non-linear)\n",
        "\n",
        "### Subtask:\n",
        "Create a copy of the dataset (Dataset C), use a non-linear regression model (like KNN or Decision Tree) to impute missing values in the same chosen column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e6c8f8f",
        "outputId": "29cff196-5a9a-43e6-d78c-bc6ed42bcc8d"
      },
      "source": [
        "df_c = df.copy()\n",
        "target_column_imputation = 'BILL_AMT5'\n",
        "missing_rows_c = df_c[df_c[target_column_imputation].isnull()]\n",
        "non_missing_rows_c = df_c[df_c[target_column_imputation].notnull()]\n",
        "numerical_cols_c = df_c.select_dtypes(include=np.number).columns.tolist()\n",
        "feature_cols_c = [col for col in numerical_cols_c if col not in [target_column_imputation, 'ID', 'default.payment.next.month']]\n",
        "X_train_c = non_missing_rows_c[feature_cols_c]\n",
        "y_train_c = non_missing_rows_c[target_column_imputation]\n",
        "X_predict_c = missing_rows_c[feature_cols_c]\n",
        "print(f\"Shape of training features (X_train_c): {X_train_c.shape}\")\n",
        "print(f\"Shape of training target (y_train_c): {y_train_c.shape}\")\n",
        "print(f\"Shape of prediction features (X_predict_c): {X_predict_c.shape}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training features (X_train_c): (29067, 22)\n",
            "Shape of training target (y_train_c): (29067,)\n",
            "Shape of prediction features (X_predict_c): (933, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9bafbdc",
        "outputId": "b736c446-0cb7-459d-dddb-947820c5b617"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "imputer.fit(X_train_c)\n",
        "X_train_c_imputed = imputer.transform(X_train_c)\n",
        "X_predict_c_imputed = imputer.transform(X_predict_c)\n",
        "non_linear_reg = DecisionTreeRegressor(random_state=42)\n",
        "non_linear_reg.fit(X_train_c_imputed, y_train_c)\n",
        "predicted_values_c = non_linear_reg.predict(X_predict_c_imputed)\n",
        "df_c.loc[missing_rows_c.index, target_column_imputation] = predicted_values_c\n",
        "print(f\"\\nMissing values in '{target_column_imputation}' after non-linear regression imputation: {df_c[target_column_imputation].isnull().sum()}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in 'BILL_AMT5' after non-linear regression imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "519793e8"
      },
      "source": [
        "# Task\n",
        "Implement Part B of the assignment, which involves splitting the four datasets (A, B, C, and D) into training and testing sets, standardizing the features using `StandardScaler`, training a Logistic Regression classifier on each dataset, and evaluating the performance using a classification report. Finally, summarize the results and discuss the impact of the different imputation strategies and listwise deletion on model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc1d7ebf"
      },
      "source": [
        "## Data split\n",
        "\n",
        "### Subtask:\n",
        "For each of the three imputed datasets (A, B, C), split the data into training and testing sets. Also, create a fourth dataset (Dataset D) by simply removing all rows that contain any missing values (Listwise Deletion) from the original dataframe `df` and split it into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b716184"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_a = df_a.drop([target_variable, id_column], axis=1)\n",
        "y_a = df_a[target_variable]\n",
        "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size=0.25, random_state=42)\n",
        "X_b = df_b.drop([target_variable, id_column], axis=1)\n",
        "y_b = df_b[target_variable]\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, y_b, test_size=0.25, random_state=42)\n",
        "X_c = df_c.drop([target_variable, id_column], axis=1)\n",
        "y_c = df_c[target_variable]\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.25, random_state=42)\n",
        "df_d = df.dropna()\n",
        "X_d = df_d.drop([target_variable, id_column], axis=1)\n",
        "y_d = df_d[target_variable]\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d, test_size=0.25, random_state=42)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fa1b298"
      },
      "source": [
        "## Classifier setup\n",
        "\n",
        "### Subtask:\n",
        "Standardize the features in all four datasets (A, B, C, D) using `StandardScaler`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74475377",
        "outputId": "60ec85d0-1d85-4fdf-8312-185eb799715f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_a_scaled = scaler.fit_transform(X_train_a)\n",
        "X_test_a_scaled = scaler.transform(X_test_a)\n",
        "X_train_b_scaled = scaler.transform(X_train_b)\n",
        "X_test_b_scaled = scaler.transform(X_test_b)\n",
        "X_train_c_scaled = scaler.transform(X_train_c)\n",
        "X_test_c_scaled = scaler.transform(X_test_c)\n",
        "X_train_d_scaled = scaler.transform(X_train_d)\n",
        "X_test_d_scaled = scaler.transform(X_test_d)\n",
        "print(\"Features standardized for all datasets.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features standardized for all datasets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c63b70a"
      },
      "source": [
        "## Model evaluation\n",
        "\n",
        "### Subtask:\n",
        "Train a Logistic Regression classifier on the training set of each of the four datasets (A, B, C, D). Evaluate the performance of each model on its respective test set using a full Classification Report (Accuracy, Precision, Recall, F1-score).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c80025",
        "outputId": "a73a569f-a885-4ccb-8c49-4d3e1f9b3f7a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "cols_with_missing_b = df_b.columns[df_b.isnull().any()].tolist()\n",
        "for col in cols_with_missing_b:\n",
        "    median_val = df_b[col].median()\n",
        "    df_b[col].fillna(median_val, inplace=True)\n",
        "cols_with_missing_c = df_c.columns[df_c.isnull().any()].tolist()\n",
        "for col in cols_with_missing_c:\n",
        "    median_val = df_c[col].median()\n",
        "    df_c[col].fillna(median_val, inplace=True)\n",
        "X_a = df_a.drop([target_variable, id_column], axis=1)\n",
        "y_a = df_a[target_variable]\n",
        "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size=0.25, random_state=42)\n",
        "X_b = df_b.drop([target_variable, id_column], axis=1)\n",
        "y_b = df_b[target_variable]\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, y_b, test_size=0.25, random_state=42)\n",
        "X_c = df_c.drop([target_variable, id_column], axis=1)\n",
        "y_c = df_c[target_variable]\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.25, random_state=42)\n",
        "df_d = df.dropna()\n",
        "X_d = df_d.drop([target_variable, id_column], axis=1)\n",
        "y_d = df_d[target_variable]\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d, test_size=0.25, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_a_scaled = scaler.fit_transform(X_train_a)\n",
        "X_test_a_scaled = scaler.transform(X_test_a)\n",
        "X_train_b_scaled = scaler.transform(X_train_b)\n",
        "X_test_b_scaled = scaler.transform(X_test_b)\n",
        "X_train_c_scaled = scaler.transform(X_train_c)\n",
        "X_test_c_scaled = scaler.transform(X_test_c)\n",
        "X_train_d_scaled = scaler.transform(X_train_d)\n",
        "X_test_d_scaled = scaler.transform(X_test_d)\n",
        "log_reg_a = LogisticRegression(random_state=42)\n",
        "log_reg_a.fit(X_train_a_scaled, y_train_a)\n",
        "y_pred_a = log_reg_a.predict(X_test_a_scaled)\n",
        "print(\"Classification Report for Dataset A:\")\n",
        "print(classification_report(y_test_a, y_pred_a))\n",
        "log_reg_b = LogisticRegression(random_state=42)\n",
        "log_reg_b.fit(X_train_b_scaled, y_train_b)\n",
        "y_pred_b = log_reg_b.predict(X_test_b_scaled)\n",
        "print(\"\\nClassification Report for Dataset B:\")\n",
        "print(classification_report(y_test_b, y_pred_b))\n",
        "log_reg_c = LogisticRegression(random_state=42)\n",
        "log_reg_c.fit(X_train_c_scaled, y_train_c)\n",
        "y_pred_c = log_reg_c.predict(X_test_c_scaled)\n",
        "print(\"\\nClassification Report for Dataset C:\")\n",
        "print(classification_report(y_test_c, y_pred_c))\n",
        "log_reg_d = LogisticRegression(random_state=42)\n",
        "log_reg_d.fit(X_train_d_scaled, y_train_d)\n",
        "y_pred_d = log_reg_d.predict(X_test_d_scaled)\n",
        "print(\"\\nClassification Report for Dataset D:\")\n",
        "print(classification_report(y_test_d, y_pred_d))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-992672612.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_b[col].fillna(median_val, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Dataset A:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89      5873\n",
            "           1       0.67      0.23      0.34      1627\n",
            "\n",
            "    accuracy                           0.81      7500\n",
            "   macro avg       0.75      0.60      0.62      7500\n",
            "weighted avg       0.79      0.81      0.77      7500\n",
            "\n",
            "\n",
            "Classification Report for Dataset B:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89      5873\n",
            "           1       0.67      0.23      0.35      1627\n",
            "\n",
            "    accuracy                           0.81      7500\n",
            "   macro avg       0.75      0.60      0.62      7500\n",
            "weighted avg       0.79      0.81      0.77      7500\n",
            "\n",
            "\n",
            "Classification Report for Dataset C:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89      5873\n",
            "           1       0.67      0.23      0.35      1627\n",
            "\n",
            "    accuracy                           0.81      7500\n",
            "   macro avg       0.75      0.60      0.62      7500\n",
            "weighted avg       0.79      0.81      0.77      7500\n",
            "\n",
            "\n",
            "Classification Report for Dataset D:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88      5232\n",
            "           1       0.71      0.23      0.35      1557\n",
            "\n",
            "    accuracy                           0.80      6789\n",
            "   macro avg       0.76      0.60      0.62      6789\n",
            "weighted avg       0.79      0.80      0.76      6789\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b24d563"
      },
      "source": [
        "# Task\n",
        "Generate a summary table comparing the performance metrics (especially F1-score) of the four models (Median Imputation, Linear Regression Imputation, Non-Linear Regression Imputation, and Listwise Deletion) and discuss the trade-off between Listwise Deletion and Imputation, compare the performance of Linear vs. Non-Linear Regression imputation methods, and conclude with a recommendation on the best strategy for handling missing data in this scenario, justifying the answer by referencing both the classification performance metrics and the conceptual implications of each method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02314ca4"
      },
      "source": [
        "## Results comparison\n",
        "\n",
        "### Subtask:\n",
        "Extract the performance metrics (especially F1-score) from the classification reports for each of the four models and create a summary table.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "97d541aa",
        "outputId": "c974d195-2127-4669-be97-ba2499a53cc8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "report_a = classification_report(y_test_a, y_pred_a, output_dict=True)\n",
        "report_b = classification_report(y_test_b, y_pred_b, output_dict=True)\n",
        "report_c = classification_report(y_test_c, y_pred_c, output_dict=True)\n",
        "report_d = classification_report(y_test_d, y_pred_d, output_dict=True)\n",
        "\n",
        "performance_data = {\n",
        "    'Metric': ['Precision (0)', 'Recall (0)', 'F1-score (0)', 'Precision (1)', 'Recall (1)', 'F1-score (1)', 'Accuracy'],\n",
        "    'Dataset A': [report_a['0']['precision'], report_a['0']['recall'], report_a['0']['f1-score'],\n",
        "                  report_a['1']['precision'], report_a['1']['recall'], report_a['1']['f1-score'],\n",
        "                  report_a['accuracy']],\n",
        "    'Dataset B': [report_b['0']['precision'], report_b['0']['recall'], report_b['0']['f1-score'],\n",
        "                  report_b['1']['precision'], report_b['1']['recall'], report_b['1']['f1-score'],\n",
        "                  report_b['accuracy']],\n",
        "    'Dataset C': [report_c['0']['precision'], report_c['0']['recall'], report_c['0']['f1-score'],\n",
        "                  report_c['1']['precision'], report_c['1']['recall'], report_c['1']['f1-score'],\n",
        "                  report_c['accuracy']],\n",
        "    'Dataset D': [report_d['0']['precision'], report_d['0']['recall'], report_d['0']['f1-score'],\n",
        "                  report_d['1']['precision'], report_d['1']['recall'], report_d['1']['f1-score'],\n",
        "                  report_d['accuracy']]\n",
        "}\n",
        "\n",
        "performance_df = pd.DataFrame(performance_data)\n",
        "display(performance_df)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Metric  Dataset A  Dataset B  Dataset C  Dataset D\n",
              "0  Precision (0)   0.819833   0.820003   0.820003   0.810100\n",
              "1     Recall (0)   0.968500   0.968840   0.968840   0.971904\n",
              "2   F1-score (0)   0.887987   0.888230   0.888230   0.883656\n",
              "3  Precision (1)   0.670819   0.673797   0.673797   0.712891\n",
              "4     Recall (1)   0.231715   0.232329   0.232329   0.234425\n",
              "5   F1-score (1)   0.344450   0.345521   0.345521   0.352827\n",
              "6       Accuracy   0.808667   0.809067   0.809067   0.802769"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46dc1db3-f046-4937-861c-1720b70c66d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Dataset A</th>\n",
              "      <th>Dataset B</th>\n",
              "      <th>Dataset C</th>\n",
              "      <th>Dataset D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Precision (0)</td>\n",
              "      <td>0.819833</td>\n",
              "      <td>0.820003</td>\n",
              "      <td>0.820003</td>\n",
              "      <td>0.810100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Recall (0)</td>\n",
              "      <td>0.968500</td>\n",
              "      <td>0.968840</td>\n",
              "      <td>0.968840</td>\n",
              "      <td>0.971904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F1-score (0)</td>\n",
              "      <td>0.887987</td>\n",
              "      <td>0.888230</td>\n",
              "      <td>0.888230</td>\n",
              "      <td>0.883656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Precision (1)</td>\n",
              "      <td>0.670819</td>\n",
              "      <td>0.673797</td>\n",
              "      <td>0.673797</td>\n",
              "      <td>0.712891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Recall (1)</td>\n",
              "      <td>0.231715</td>\n",
              "      <td>0.232329</td>\n",
              "      <td>0.232329</td>\n",
              "      <td>0.234425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>F1-score (1)</td>\n",
              "      <td>0.344450</td>\n",
              "      <td>0.345521</td>\n",
              "      <td>0.345521</td>\n",
              "      <td>0.352827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>0.808667</td>\n",
              "      <td>0.809067</td>\n",
              "      <td>0.809067</td>\n",
              "      <td>0.802769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46dc1db3-f046-4937-861c-1720b70c66d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46dc1db3-f046-4937-861c-1720b70c66d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46dc1db3-f046-4937-861c-1720b70c66d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2526b183-82b1-4d0c-958b-b041ae0c4299\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2526b183-82b1-4d0c-958b-b041ae0c4299')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2526b183-82b1-4d0c-958b-b041ae0c4299 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_eef65d7a-e663-4712-8f09-41816008ce4c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('performance_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eef65d7a-e663-4712-8f09-41816008ce4c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('performance_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "performance_df",
              "summary": "{\n  \"name\": \"performance_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Precision (0)\",\n          \"Recall (0)\",\n          \"F1-score (1)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dataset A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.281698673662139,\n        \"min\": 0.23171481253841425,\n        \"max\": 0.9684999148646347,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8198328048428942,\n          0.9684999148646347,\n          0.3444495203289173\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dataset B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2814547243011864,\n        \"min\": 0.23232944068838352,\n        \"max\": 0.9688404563255576,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8200028822596916,\n          0.9688404563255576,\n          0.34552102376599636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dataset C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2814547243011864,\n        \"min\": 0.23232944068838352,\n        \"max\": 0.9688404563255576,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8200028822596916,\n          0.9688404563255576,\n          0.34552102376599636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dataset D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27848761185009097,\n        \"min\": 0.23442517662170842,\n        \"max\": 0.9719036697247706,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8101003664170783,\n          0.9719036697247706,\n          0.35282745287578543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85374728"
      },
      "source": [
        "Discussion and Recommendation:\n",
        "\n",
        "Trade-offs between Listwise Deletion and Imputation:\n",
        "Listwise deletion (Dataset D) resulted in removing rows with any missing values, leading to a smaller dataset size compared to the imputed datasets (A, B, C).\n",
        "Dataset D size: 27156 rows, compared to Datasets A, B, C size: 30000 rows.\n",
        "This reduction in data size can be a significant drawback, especially if the proportion of missing data is large, as it can lead to a loss of potentially valuable information and reduced statistical power.\n",
        "However, listwise deletion is simple and avoids introducing bias from potentially inaccurate imputed values if the MAR assumption is violated.\n",
        "Looking at the performance metrics, Dataset D (Listwise Deletion) shows a slightly higher F1-score for class 1 (defaults) compared to the imputed datasets (0.3528 vs ~0.345), and a slightly lower accuracy (0.8028 vs ~0.809). This suggests that while it retains potentially 'cleaner' data, the reduction in sample size might slightly impact overall accuracy but could improve the model's ability to identify the minority class in the remaining data.\n",
        "\n",
        "Comparison of Linear vs. Non-Linear Regression Imputation:\n",
        "Both Linear Regression Imputation (Dataset B) and Non-Linear Regression Imputation (Dataset C, using Decision Tree) produced nearly identical classification reports. Their precision, recall, F1-scores, and accuracy are almost the same as Simple Median Imputation (Dataset A).\n",
        "This indicates that for the specific MAR mechanism introduced (missingness in BILL_AMT5, PAY_5, LIMIT_BAL related to AGE > median AGE) and the Logistic Regression model used, the more complex regression imputation methods did not provide a significant performance gain over simply imputing with the median.\n",
        "This could be due to several reasons: the relationships between the missing features and other features might not be strongly linear or non-linear in a way that significantly improves prediction for imputation purposes, or the Logistic Regression model might not be sensitive enough to the nuances introduced by the regression imputations compared to median imputation for this specific task.\n",
        "\n",
        "Recommendation:\n",
        "Based on the analysis, Simple Median Imputation (Dataset A) appears to be the most practical and effective strategy among the tested methods for this scenario.\n",
        "Although Listwise Deletion (Dataset D) showed a marginally better F1-score for the minority class, it came at the cost of discarding a substantial portion of the data (around 10%). In many real-world scenarios, retaining as much data as possible is crucial.\n",
        "The regression imputation methods (Datasets B and C) did not demonstrate a clear advantage over the simpler median imputation in terms of classification performance on the test set, despite being more computationally intensive and relying on the MAR assumption.\n",
        "Given its simplicity, computational efficiency, and comparable performance to the more complex methods for this specific MAR scenario, Median Imputation is the recommended strategy. It effectively handles missing values without the data loss of listwise deletion or the added complexity and lack of clear performance benefit seen with regression imputation in this case.\n",
        "It's important to note that the best imputation strategy can be highly dependent on the nature of the missing data (MCAR, MAR, MNAR), the relationships within the data, and the downstream modeling task. For MNAR data, more sophisticated methods beyond those tested here would likely be necessary."
      ]
    }
  ]
}